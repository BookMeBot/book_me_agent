import os
from dotenv import load_dotenv

from langchain.agents import initialize_agent
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import ChatOpenAI

load_dotenv()
# Language Model
llm = ChatOpenAI(model="gpt-4o", temperature=0, api_key=os.getenv("OPENAI_API_KEY"))

# Generalized QA Prompt
qa_prompt = PromptTemplate(
    input_variables=["context", "question"],
    template=(
        "You are an assistant that answers questions based on the provided context.\n"
        "Context: {context}\n"
        "Question: {question}\n"
        "Provide a concise, helpful answer."
    ),
)

# QA Chain
qa_chain = LLMChain(llm=llm, prompt=qa_prompt)


def answer_question(context, question):
    """
    Answer a user's question based on dynamic context.
    :param context: Context string (hotel, listing, or neighborhood details).
    :param question: User query.
    :return: Answer generated by the agent.
    """
    return qa_chain.run({"context": context, "question": question})
